from __future__ import division
import sys
import collections  # using OrderedDict
from table import *
from where2 import *
from dtree import *
from Abcd import *
import pdb
import random
from base import *
from newabcd import *


# ++++++++++++++++++++++++++++++++++++++++++++++++++++
# Preparing training, testing, data
# ++++++++++++++++++++++++++++++++++++++++++++++++++++

def csv2py(f):
  if isinstance(f, list):
    tbl = [table(src) for src in f]  # tbl is a list of tables
    t = tbl[0]
    for i in range(1, len(tbl)):
      t._rows += tbl[i]._rows
    tbl = t
  else:
    tbl = table(f)
  tbl_num = tbl  # no symbol data col in defect data sets.
  x = data(indep=[x.name for x in tbl_num.indep[:-1]], less=[x.name for x in tbl_num.depen],
           _rows=[row.cells for row in tbl_num._rows])
  return x


def clustertbl(f, tree, num2sym={}):
  row = []
  if isinstance(f, list):
    tbl1 = tbl = table(f[0])
  else:
    tbl1 = tbl = table(f)
  newheader = Num()
  newheader.col = len(tbl.headers)
  newheader.name = "=klass"
  tbl1.headers += [newheader]  # tbl1 : the new table with cluster ID
  count = 0
  for k, _ in leaves(tree):
    for j in k.val:
      tmp = j.cells
      tmp.append(str(count))
      tmp.append(j.cells[tbl1.depen[0].col])
      j.update(cells=tmp)
      row.append(j.cells)
    count += 1
  tbl1 = clone(tbl1, row)
  return tbl1, row


def buildtestdata1(f, isdefect = False):  # build testdata from table
  actual = []
  testdata = []
  if isinstance(f, list):
    tbl = [table(src) for src in f]  # tbl is a list of tables
    t = tbl[0]
    for i in range(1, len(tbl)):
      t._rows += tbl[i]._rows
    tbl = t
  else:
    tbl = table(f)
  for row in tbl._rows:
    if isdefect:
      actual += ["Defective" if row.cells[tbl.depen[0].col] > 0 else "Non-Defective"]
    else:
      actual +=[str(row.cells[tbl.depen[0].col])]
    testdata += [row]
  return testdata, actual


# ++++++++++++++++++++++++++++++++++++++++++++++++++++
# Leaves related function
# ++++++++++++++++++++++++++++++++++++++++++++++++++++


def gotoleaf(testdata, tree, opt=The.tree):
  goleaf = []
  for row in testdata:
    goleaf += [apex(row, tree, opt)]
  return goleaf


def leafscore(leaf):
  score = []
  for row in leaf.rows:
    score += [row.cells[-1]]
  n = len(score)
  score = sorted(score)
  if The.option.mean:
    value = float(sum(score) / n)
  else:
    value = median(score)
  return value


# ++++++++++++++++++++++++++++++++++++++++++++++++++++
# Print tree function
# ++++++++++++++++++++++++++++++++++++++++++++++++++++

def showTdiv(n, lvl=-1):
  if not The.option.showDTree:
    return
  if n.f:
    say(('|..' * lvl) + str(n.f.name) + "=" + str(n.val) + "\t:" + str(n.mode) + " #" + str(nmodes(n)))
  if n.kids:
    nl()
    for k in n.kids:
      showTdiv(k, lvl + 1)
  else:
    s = classStats(n)
    print ' ' + str(int(100 * s.counts[s.mode()] / len(n.rows))) + '% * ' + str(len(n.rows)) + '  leaf #' + str(
      n.leafid) + '  score:' + str(round(n.score, 2))


# ++++++++++++++++++++++++++++++++++++++++++++++++++++
# statistics function
# ++++++++++++++++++++++++++++++++++++++++++++++++++++
def _Abcd(testleaf, testdata, actual):
  test = []
  # abcd = Abcd(db='Traing', rx='Testing')
  def isDef(x):
    return "Defective" if x > The.option.threshold else "Non-Defective"

  for leaf, data in zip(testleaf, testdata):
    # give the mean(median is another choice) of all rows in this point
    # pdb.set_trace()
    test += [isDef(leafscore(leaf))]
  # for actual, predicted in zip(train, test):
  #   abcd.tell(actual, predicted)
  # abcd.header()
  # score = abcd.ask()
  score = sk_abcd(test, actual)
  return score


def buildtdiv(tbl):
  row = map(lambda x: x.cells, tbl._rows)
  t = discreteNums(tbl, row)
  tree = tdiv(t)
  # showTdiv(tree)
  return tree


# ++++++++++++++++++++++++++++++++++++++++++++++++++++
# We start at hereee!
# ++++++++++++++++++++++++++++++++++++++++++++++++++++

def main():
  global The
  The.option.showWhere = False
  The.option.showDTree = False
  testdata, actual = buildtestdata1(The.data.predict)
  m = csv2py(The.data.train)
  Init(m)  # init WHere!!
  tree = where2(m, m._rows)  # tree generated by clustering
  tbl1, row = clustertbl(The.data.train, tree)  # new table with cluster ID
  The.option.clustering = True
  Dtree = buildtdiv(tbl1)
  testleaf = gotoleaf(testdata, Dtree)  # all the leaves the testdata should go
  score = _Abcd(testleaf, testdata, actual)
  return score


if __name__ == "__main__":
  eval(cmd())
